# LLM-Planner: Few-Shot Grounded Planning for Embodied Agents with Large Language Models 

Code for [LLM-Planner](https://arxiv.org/abs/2212.04088).

Check [project website](https://dki-lab.github.io/LLM-Planner/) for an overview and a demo.

## What's Here
- A high-level prompt generator and kNN dataset from our paper. Just bring your low-level controller (and an LLM)!

## Quickstart
`
python hlp_planner.py
`

This commands uses the KNN dataset to generate a high-level plan for an example task.
Check out the code for more details.

## Implementation Examples
We provide examples of how the community has been using our work. We appreciate everyone's interest!

- **[DEDER](https://arxiv.org/abs/2412.11499)** – *ICML 2024*
- **[ReALFRED](https://arxiv.org/abs/2407.18550)** – *ECCV 2024*
- **[NeSyC](https://arxiv.org/abs/2503.00870)** – *ICLR 2025*
- **[Socratic Planner](https://arxiv.org/abs/2404.15190)** – *ICRA 2025*

## Citation Information

```
@InProceedings{song2023llmplanner,
  author    = {Song, Chan Hee and Wu, Jiaman and Washington, Clayton and Sadler, Brian M. and Chao, Wei-Lun and Su, Yu},
  title     = {LLM-Planner: Few-Shot Grounded Planning for Embodied Agents with Large Language Models},
  booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
  month     = {October},
  year      = {2023},
}
```

## Acknowledgements

We thank [OSUNLP](https://x.com/osunlp) for providing valuable feedback and suggestions.

## License

- LLM-Planner - MIT License

## Contact

Questions or issues? File an issue or contact [Luke Song](https://chanh.ee)

